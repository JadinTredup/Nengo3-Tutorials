{
 "metadata": {
  "name": "",
  "signature": "sha256:6d861814b4d9273ddf9ce743fe4efa3e1c5a379e948a342d8f4a8e09c2d0b4d2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Question Answering with Control\n",
      "\n",
      "This model shows a form of question answering where statements and questions are supplied through a single 'visual input' and the replies are produced in a 'motor output' as discussed in the book. You will implement this by using the basal ganglia to store and retrieve information from working memory in response to visual input. More specifically, the basal ganglia decides what to do with the information in the visual channel based on its content (i.e. whether it is a statement or a question).\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Setup the environment\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "%matplotlib inline\n",
      "\n",
      "import nengo\n",
      "from nengo.spa import Vocabulary\n",
      "from nengo.spa import BasalGanglia\n",
      "from nengo.spa import Thalamus\n",
      "from nengo.dists import Uniform"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "javascript": [
        "\n",
        "        require([\"widgets/js/widget\", \"widgets/js/manager\"],\n",
        "            function(widget, manager) {\n",
        "          if (typeof widget.DOMWidgetView == 'undefined') {\n",
        "            widget = IPython;\n",
        "          }\n",
        "          if (typeof manager.WidgetManager == 'undefined') {\n",
        "            manager = IPython;\n",
        "          }\n",
        "\n",
        "          var NengoProgressBar = widget.DOMWidgetView.extend({\n",
        "            render: function() {\n",
        "              // $el is the DOM of the widget\n",
        "              this.$el.css({width: '100%', marginBottom: '0.5em'});\n",
        "              this.$el.html([\n",
        "                '<div style=\"',\n",
        "                    'width: 100%;',\n",
        "                    'border: 1px solid #cfcfcf;',\n",
        "                    'border-radius: 4px;',\n",
        "                    'text-align: center;',\n",
        "                    'position: relative;\">',\n",
        "                  '<div class=\"pb-text\" style=\"',\n",
        "                      'position: absolute;',\n",
        "                      'width: 100%;\">',\n",
        "                    '0%',\n",
        "                  '</div>',\n",
        "                  '<div class=\"pb-bar\" style=\"',\n",
        "                      'background-color: #bdd2e6;',\n",
        "                      'width: 0%;',\n",
        "                      'transition: width 0.1s linear;\">',\n",
        "                    '&nbsp;',\n",
        "                  '</div>',\n",
        "                '</div>'].join(''));\n",
        "            },\n",
        "\n",
        "            update: function() {\n",
        "              this.$el.css({width: '100%', marginBottom: '0.5em'});\n",
        "              var progress = 100 * this.model.get('progress');\n",
        "              var text = this.model.get('text');\n",
        "              this.$el.find('div.pb-bar').width(progress.toString() + '%');\n",
        "              this.$el.find('div.pb-text').text(text);\n",
        "            },\n",
        "          });\n",
        "\n",
        "          manager.WidgetManager.register_widget_view(\n",
        "            'NengoProgressBar', NengoProgressBar);\n",
        "        });"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Javascript at 0x7f650264d350>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Create the model\n",
      "\n",
      "Here again, you will use the SPA module in nengo2 to implement this model with parameters as described in the book. Basal ganglia and thalamus are built into SPA and you can directly specify the actions/rules (based on which basal ganglia makes a decision) using the built-in 'Actions' class in SPA. This class takes a string definition of the action as an input as shown in the code where '-->' is used to split the action into condition and effect, otherwise it is treated as having no condition and just effect.\n",
      "\n",
      "When you run the network, it will start by binding `RED` and `CIRCLE` and then binding `BLUE` and `SQUARE` so the memory essentially has `RED * CIRCLE + BLUE * SQUARE`. It does this because it is told that `RED * CIRCLE` is a STATEMENT (i.e. `RED * CIRCLE + STATEMENT` in the code) as is `BLUE * SQUARE`. Then it is presented with something like `QUESTION + RED` (i.e., \"What is red?\"). The basal ganglia then reroutes that input to be compared to what is in working memory and the result shows up in the motor channel."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dim=40       # Number of dimensions \n",
      "N=30           # Neurons per dimension\n",
      "N_conv=70      # Number of neurons per dimension in bind/unbind populations\n",
      "N_mem=50       # Number of neurons per dimension in memory population\n",
      "\n",
      "rng = np.random.RandomState(15)\n",
      "vocab = Vocabulary(dimensions=dim, rng=rng, max_similarity=0.1)\n",
      "\n",
      "A = vocab.parse('STATEMENT+RED*CIRCLE').v\n",
      "B = vocab.parse('STATEMENT+BLUE*SQUARE').v\n",
      "C = vocab.parse('QUESTION+BLUE').v\n",
      "D = vocab.parse('QUESTION+CIRCLE').v\n",
      "\n",
      "M = vocab.parse('STATEMENT').v\n",
      "N = vocab.parse('QUESTION').v\n",
      "\n",
      "\n",
      "def test(x, trans0):\n",
      "    scale = np.linalg.norm(x) * np.linalg.norm(trans0)\n",
      "    if scale == 0:\n",
      "        return 0\n",
      "    if np.dot(x, trans0) / scale > 0:\n",
      "        test = 1\n",
      "    else:    \n",
      "        test = 0\n",
      "    #print \"trans0: \", test\n",
      "    return test\n",
      "\n",
      "\n",
      "print \"M: \", test(A,M)\n",
      "print \"N: \", test(A,N)\n",
      "print \"\\n\"\n",
      "\n",
      "print \"M: \", test(B,M)\n",
      "print \"N: \", test(B,N)\n",
      "print \"\\n\"\n",
      "\n",
      "print \"M: \", test(C,M)\n",
      "print \"N: \", test(C,N)\n",
      "print \"\\n\"\n",
      "\n",
      "print \"M: \", test(D,M)\n",
      "print \"N: \", test(D,N)\n",
      "print \"\\n\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "M:  1\n",
        "N:  0\n",
        "\n",
        "\n",
        "M:  1\n",
        "N:  0\n",
        "\n",
        "\n",
        "M:  0\n",
        "N:  1\n",
        "\n",
        "\n",
        "M:  0\n",
        "N:  1\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dim=50        # Number of dimensions \n",
      "N=30           # Neurons per dimension\n",
      "N_conv=70      # Number of neurons per dimension in bind/unbind populations\n",
      "N_mem=50       # Number of neurons per dimension in memory population\n",
      "\n",
      "\n",
      "rng = np.random.RandomState(15)\n",
      "vocab = Vocabulary(dimensions=dim, rng=rng, max_similarity=0.1)\n",
      "model = nengo.Network(label='Question Answering with Control', seed=15)\n",
      "\n",
      "vocab.parse('CIRCLE+BLUE+RED+SQUARE+QUESTION+STATEMENT')\n",
      "\n",
      "with model:\n",
      "    #Ensembles\n",
      "    visual = nengo.networks.EnsembleArray(n_neurons=N, n_ensembles=dim, max_rates=Uniform(100,300), label='Visual')\n",
      "    channel = nengo.networks.EnsembleArray(n_neurons=N, n_ensembles=dim, label='Channel')\n",
      "    motor = nengo.networks.EnsembleArray(n_neurons=N, n_ensembles=dim, label='Motor')   \n",
      "    \n",
      "    #Creating an integrator/memory\n",
      "    \"\"\"if (dim<8):\n",
      "        memory = nengo.Ensemble(n_neurons=N_mem*dim, dimensions=dim, label='Memory')\n",
      "        nengo.Connection(memory, memory, synapse=0.4)     \n",
      "    else:\"\"\"\n",
      "    memory = nengo.networks.EnsembleArray(n_neurons=N, n_ensembles=dim, label='Memory')\n",
      "    nengo.Connection(memory.output, memory.input, synapse=0.4)     \n",
      "    \n",
      "    ZERO=[0]*dim \n",
      "    trans0 = np.matrix(np.array(vocab.parse('STATEMENT').v))\n",
      "    trans1 = np.matrix(np.array(vocab.parse('QUESTION').v))\n",
      "    \n",
      "    \n",
      "    def visual_input(t):\n",
      "        if 0.1 < t < 0.3:\n",
      "            return vocab.parse('STATEMENT+RED*CIRCLE').v\n",
      "        elif 0.35 < t < 0.5:\n",
      "            return vocab.parse('STATEMENT+BLUE*SQUARE').v\n",
      "        elif 0.55 < t < 0.7:\n",
      "            return vocab.parse('QUESTION+BLUE').v\n",
      "        elif 0.75 < t < 0.9:\n",
      "            return vocab.parse('QUESTION+CIRCLE').v\n",
      "        else:\n",
      "            return ZERO\n",
      "\n",
      "    def xBiased(x):\n",
      "        return [x[0]+1]\n",
      "    \n",
      "    def compare0(x):\n",
      "        scale = np.linalg.norm(x) * np.linalg.norm(trans0)\n",
      "        if scale == 0:\n",
      "            return 0\n",
      "        return np.dot(x, trans0) / scale\n",
      "    \n",
      "    def compare1(x):\n",
      "        scale = np.linalg.norm(x) * np.linalg.norm(trans1)\n",
      "        if scale == 0:\n",
      "            return 0\n",
      "        return np.dot(x, trans1) / scale\n",
      "    \n",
      "    \n",
      "    \n",
      "    input = nengo.Node(output=visual_input, size_out=dim)\n",
      "    \n",
      "    nengo.Connection(input, visual.input)\n",
      "    nengo.Connection(visual.output, channel.input, synapse=0.02)\n",
      "    nengo.Connection(channel.output, memory.input)\n",
      "    \n",
      "    #create the unbind network\n",
      "    unbind = nengo.networks.CircularConvolution(n_neurons=N_conv*dim, dimensions=dim, invert_a=True)\n",
      "    nengo.Connection(visual.output, unbind.A)\n",
      "    nengo.Connection(memory.output, unbind.B)\n",
      "    nengo.Connection(unbind.output, motor.input)\n",
      "    \n",
      "    BG = nengo.networks.BasalGanglia(dimensions=2)  \n",
      "    thal = nengo.networks.Thalamus(dimensions=2)\n",
      "    nengo.Connection(BG.output, thal.input, transform=[[-3,0], [0,-3]], synapse=0.01)\n",
      "    \n",
      "    nengo.Connection(visual.output, BG.input[0], transform=trans0)\n",
      "    nengo.Connection(visual.output, BG.input[1], transform=trans1) \n",
      "    \n",
      "    gate1 = nengo.Ensemble(N, 1, label='Gate1')\n",
      "    nengo.Connection(thal.output[0], gate1)\n",
      "        \n",
      "    gate2 = nengo.Ensemble(N, 1, label='Gate2')\n",
      "    nengo.Connection(thal.output[1], gate1)   \n",
      "    \n",
      "    for ensemble in channel.ea_ensembles:\n",
      "        nengo.Connection(gate1, ensemble, function=xBiased)\n",
      "        \n",
      "    for ensemble in motor.ea_ensembles:\n",
      "        nengo.Connection(gate2, ensemble, function=xBiased)  \n",
      "      "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Provide input to the model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Add Probes to Collect Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with model:\n",
      "    Visual_p = nengo.Probe(visual.output, synapse=0.03)\n",
      "    Motor_p = nengo.Probe(motor.output, synapse=0.03)\n",
      "    Memory_p = nengo.Probe(memory.output, synapse=0.03)\n",
      "    actions = nengo.Probe(thal.output, synapse=0.01)\n",
      "    utility = nengo.Probe(BG.input, synapse=0.01)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Run The Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sim = nengo.Simulator(model)    #Create the simulator\n",
      "sim.run(1.2)    #Run it for 1.2 seconds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Plot The Results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"fig = plt.figure(figsize=(12,8))\n",
      "p1 = fig.add_subplot(5,1,1)\n",
      "#p1.plot(sim.trange(), model.similarity(sim.data, Visual_p))\n",
      "plt.plot(sim.trange(), sim.data[Visual_p])\n",
      "#p1.legend(model.get_output_vocab('Visual').keys, fontsize='x-small')\n",
      "p1.set_ylabel('Visual')\n",
      "\n",
      "p2 = fig.add_subplot(5,1,2)\n",
      "p2.plot(sim.trange(), sim.data[Memory_p])\n",
      "#p2.legend(model.get_output_vocab('Memory').keys, fontsize='x-small')\n",
      "p2.set_ylabel('Memory')\n",
      "\n",
      "p3 = fig.add_subplot(5,1,3)\n",
      "p3.plot(sim.trange(), sim.data[Motor_p])\n",
      "#p3.legend(model.get_output_vocab('Motor').keys, fontsize='x-small')\n",
      "p3.set_ylabel('Motor')\n",
      "\n",
      "fig.subplots_adjust(hspace=0.2)\"\"\"\n",
      "\n",
      "\n",
      "plt.figure(figsize=(10, 10))\n",
      "\n",
      "plt.subplot(6, 1, 1)\n",
      "plt.plot(sim.trange(), nengo.spa.similarity(sim.data[Visual_p], vocab))\n",
      "plt.legend(vocab.keys, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0, fontsize=9)\n",
      "plt.ylabel(\"Visual\");\n",
      "\n",
      "plt.subplot(6, 1, 2)\n",
      "plt.plot(sim.trange(), nengo.spa.similarity(sim.data[Memory_p], vocab))\n",
      "plt.legend(vocab.keys, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0, fontsize=9)\n",
      "plt.ylabel(\"Memory\");\n",
      "\n",
      "plt.subplot(6, 1, 3)\n",
      "plt.plot(sim.trange(), nengo.spa.similarity(sim.data[Motor_p], vocab))\n",
      "plt.legend(vocab.keys, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0, fontsize=9)\n",
      "plt.ylabel(\"Motor\");\n",
      "\n",
      "plt.subplot(6, 1, 4)\n",
      "plt.plot(sim.trange(), sim.data[actions])\n",
      "plt.legend(vocab.keys, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0, fontsize=9)\n",
      "plt.ylabel(\"Action\");\n",
      "\n",
      "plt.subplot(6, 1, 5)\n",
      "plt.plot(sim.trange(), sim.data[utility])\n",
      "plt.legend(vocab.keys, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0, fontsize=9)\n",
      "plt.ylabel(\"Utility\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyError",
       "evalue": "<Probe at 0x7f64fcbc1690 of 'output' of <Node \"output\">>",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-7-821e0dec82d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#p1.plot(sim.trange(), model.similarity(sim.data, Visual_p))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mVisual_p\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#p1.legend(model.get_output_vocab('Visual').keys, fontsize='x-small')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Visual'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/ctnuser/git/nengo/nengo/simulator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyError\u001b[0m: <Probe at 0x7f64fcbc1690 of 'output' of <Node \"output\">>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAsUAAABuCAYAAADPj24cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wf2VTrKSYTljwAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f64fcfc9690>"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The graphs above show that when the input to the Visual system is a `STATEMENT`, there is no response from the Motor system and the input is stored in the Memory. However, when the input to the Visual system is a `QUESTION`, the Motor system responds with the appropriate answer. For instance, when the input to Visual system is `CIRCLE` the output from the motor system is `RED`."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}